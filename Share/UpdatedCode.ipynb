{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Tflite: 1 \n",
      " Onnx: 2  \n",
      " NCNN: 3 \n",
      " PyTorch: 4 \n",
      " Cancel: 5 \n",
      " 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selected: yolov8sModel.pt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Chose Working Model:\n",
    "\n",
    "'''\n",
    "\n",
    "while True:\n",
    "    userInput = input(\"Tflite: 1 \\n Onnx: 2  \\n NCNN: 3 \\n PyTorch: 4 \\n Cancel: 5 \\n\")\n",
    "\n",
    "    if userInput == '1':\n",
    "        modelName = 'yolov8sModel_float32.tflite'\n",
    "        break\n",
    "    elif userInput == '2':\n",
    "        modelName = 'yolov8sModel.onnx'\n",
    "        break\n",
    "    elif userInput == '3':\n",
    "        modelName = 'yolov8sModel_ncnn_model'\n",
    "        break\n",
    "    elif userInput == '4':\n",
    "        modelName = 'yolov8sModel.pt'\n",
    "        break\n",
    "    elif userInput == '5':\n",
    "        print(\"Exiting input operation\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection. Please try again.\")\n",
    "\n",
    "\n",
    "print(f\"Model Selected: {modelName}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model Directory:\n",
      "C:\\Users\\12108\\fiftyone\\detect\\MODEL\\yolov8sModel.pt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get Model Directory: \n",
    "\n",
    "'''\n",
    "\n",
    "if os.path.exists(modelName):\n",
    "    modelDirectory = os.path.join(os.getcwd() , modelName )\n",
    "    print(f\"Current Model Directory:\\n{modelDirectory}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Please ensure {modelName} is in the current working directory: \\nCurrent Directory: {os.getcwd()}\")\n",
    "\n",
    "\n",
    "model = YOLO(modelDirectory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 278.3ms\n",
      "Speed: 10.4ms preprocess, 278.3ms inference, 20.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_frame_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Update previous positions\u001b[39;00m\n\u001b[0;32m     67\u001b[0m prev_positions[track_id] \u001b[38;5;241m=\u001b[39m center\n\u001b[1;32m---> 68\u001b[0m prev_frame_time \u001b[38;5;241m=\u001b[39m \u001b[43mnew_frame_time\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Draw bounding box and label on frame\u001b[39;00m\n\u001b[0;32m     71\u001b[0m color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_frame_time' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "OpenCV Implementation\n",
    "'''\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# FPS calculation (Start time and positioning)\n",
    "prev_frame_time = time.time()\n",
    "prev_positions = defaultdict(lambda: None)  # Track previous positions \n",
    "\n",
    "pixels_meters = 0.05                        # Adjust to setup\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Couldn't read frame from Webcam.\")\n",
    "        break\n",
    "\n",
    "    # Smaller frame = faster processing\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    # Convert frame to RGB (YOLO: RGB format)\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run inference\n",
    "    results = model(frame_rgb)\n",
    "\n",
    "    # Determine box coordinates, class ID, and confidence score\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes.xyxy[i].numpy().astype(int)        # Coordinates: results.boxes.xyxy\n",
    "            confidence = float(boxes.conf[i].numpy())      # Score: confidence of detection\n",
    "            class_id = int(boxes.cls[i].numpy())           # Class ID: results.boxes.cls\n",
    "            label = model.names[class_id]\n",
    "            \n",
    "            if label in ['car', 'truck', 'person', 'bus']:\n",
    "                x1, y1, x2, y2 = box                       # Box Coordinates\n",
    "                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                track_id = (label, i)                      # ID from label and index\n",
    "                \n",
    "                if prev_positions[track_id] is not None:\n",
    "                    prev_center = prev_positions[track_id]\n",
    "                    distance_pixels = euclidean_distance(center, prev_center)\n",
    "                    distance_meters = distance_pixels * pixels_to_meters\n",
    "                    new_frame_time = time.time()\n",
    "                    time_elapsed = new_frame_time - prev_frame_time\n",
    "                    fps = 1 / time_elapsed if time_elapsed > 0 else 1\n",
    "                    \n",
    "                    speed_mps = distance_meters * fps           # (units/s)\n",
    "                    speed_mph = speed_mps * 2.23694             # Conversion 3600s in 1 hour, 1609m in 1mi (3600/1609) \n",
    "                    \n",
    "                    #cv2.putText(frame_resized, f\"Speed: {speed_mph:.2f} mph\", (x2 - 150, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    cv2.putText(frame_resized, f\"Speed: {speed_mph:.2f} mph\", (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Update previous positions\n",
    "                prev_positions[track_id] = center\n",
    "                prev_frame_time = new_frame_time\n",
    "\n",
    "                # Draw bounding box and label on frame\n",
    "                color = (0, 0, 255)\n",
    "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame_resized, f\"{label} {confidence:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Calculate FPS\n",
    "    new_frame_time = time.time()\n",
    "    time_elapsed = new_frame_time - prev_frame_time\n",
    "    fps = 1 / time_elapsed if time_elapsed > 0 else 1\n",
    "    prev_frame_time = new_frame_time\n",
    "    \n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame_resized, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow(\"Webcam YOLO Detection\", frame_resized)\n",
    "\n",
    "    # Break the loop if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
